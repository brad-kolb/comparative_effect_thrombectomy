---
title: "Comparative effect of thrombectomy: a bayesian analysis"
format: gfm
embed-resources: true
editor: visual
execute: 
  warning: false
  error: false
  cache: false
editor_options: 
  chunk_output_type: console
---

```{r load packages, data, convenience functions}
#| echo: false
library(here)
library(tidyverse)
library(stringr)

data <- read_csv(here("data", "clean_data.csv"), show_col_types = FALSE)

group_summary <- readRDS(here("fits", "gq1_summary.RDS"))

gq1 <- readRDS(here("fits", "gq1.RDS"))

comma <- function(x) format(x, digits = 2, nsmall = 1, big.mark = ",", small.mark = ",")
```

## Abstract

### Importance
22 randomized clinical trials of mechanical thrombectomy for ischemic stroke have been performed, but the implications of the results for patients treated outside these trials are unclear.

### Objective
To use information from existing randomized trials to infer the range of plausible patient-level outcomes in a hypothetical future trial of thrombectomy for various types of stroke, and to present this information in easy to understand terms that can be readily employed in real-world clinical scenarios.

### Data sources
Pubmed was searched through May 2024.

### Study selection
All randomized trials of best medical management versus best medical management plus modern mechanical thrombectomy were included.

### Data extraction and synthesis
Data was extracted from 22 randomized trials. A varying-slopes varying-intercepts multilevel logistic regression was fit to the extracted data. Posterior predictive distributions for model parameters were used to calculate the range of plausible absolute treatment effects in a future trial, adjusted for stroke type.

### Main outcomes and measures
The main outcome was the expected absolute difference in the probability of functional independence in the treatment versus control arm of a new hypothetical trial of mechanical thrombectomy, adjusted for stroke type.

### Results
```{r abstract results}
#| echo: false

df <- group_summary %>% 
  filter(str_detect(variable, "rd_epred")) %>% 
  select("variable", "median", "mad", "low", "high") 

rd1 <- comma(df$median[1] * 100)
rd1low <- comma(df$low[1] * 100)
rd1high <- comma(df$high[1] * 100)

rd2 <- comma(df$median[2] * 100)
rd2low <- comma(df$low[2] * 100)
rd2high <- comma(df$high[2] * 100)

rd3 <- comma(df$median[3] * 100)
rd3low <- comma(df$low[3] * 100)
rd3high <- comma(df$high[3] * 100)

rd4 <- comma(df$median[4] * 100)
rd4low <- comma(df$low[4] * 100)
rd4high <- comma(df$high[4] * 100)

```
Conditional on data from 22 previous trials and the model used to analyze the data, thrombectomy is predicted to increase the probability of functional independence by `r rd2`% (`r rd2low`% - `r rd2high`%) in a new trial of small strokes treated in an early time window, compared to `r rd3`% (`r rd3low` - `r rd3high`%) in a new trial of small strokes treated in a late time window, `r rd4`% (`r rd4low` - `r rd4high`%), in a new trial of basilar strokes, and `r rd1`% (`r rd1low` - `r rd1high`%) in a new trial of large strokes treated in an early time window.

### Conclusions and relevance
The absolute treatment effect of thrombectomy in a future trial is predicted to be positive with at least 95% confidence across all stroke types, but the magnitude of the predicted effect is uncertain and varies substantially according to the type of stroke being treated.

## Introduction
The effectiveness of mechanical thrombectomy for stroke has been evaluated in multiple clinical trials and meta-analyses. However, traditional meta-analyses, focused on estimating average treatment effects across past trials, can be difficult to translate into guidance for individual patient care in new situations. Clinicians and patients need practical answers to questions like: "what range of outcomes might I expect with this treatment?" and "how certain can I be that this treatment will make a meaningful difference in my chances for a good outcome?" 

In this paper, we address these questions directly using a Bayesian meta-analysis of all existing thrombectomy trials. Rather than estimating the average effect in past trials, we use the information embedded in the outcomes of these trials to predict the range of plausible outcomes for future patients. By focusing on prediction rather than estimation and absolute rather than relative effects, we move beyond statistical significance to a rigorous quantification of clinical importance, providing evidence-based probability estimates that clinicians can use when discussing treatment decisions with patients and families.

# Methods
This meta-analysis was conducted according to the preferred reporting items for systematic reviews and meta-analysis (PRISMA) guidelines. The initial analysis plan was preregistered on the Open Science Framework. We categorized all thrombectomy trials into four clinically distinct categories: early-window small core strokes (EW-SC), late-window small core strokes (LW-SC), early-window large core strokes (EW-LC), and basilar artery strokes (BS). This classification reflects key differences in patient populations that could influence treatment effectiveness. The primary outcome was functional independence at 6 months followup in the intention-to-treat population. To analyze outcomes across these stroke types, we used a multilevel logistic regression model with varying slopes and varying intercepts. This model accounts for both within-trial and between-trial variation in baseline risk and treatment effect, adjusting outcomes according to stroke category. The model was implemented in Stan, a probabilistic programming language designed for rigorous uncertainty quantification. Convergence and model diagnostics were assessed according to expert recommendations, and this information is fully reported in the appendix. Sensitivity checks for the priors and the likelihood were performed. Treatment effects are reported as the median of posterior predictive distribution for the corresponding quantity in the model. Uncertainty for this estimate is expressed with the 95% posterior interval - a range that can be interpreted as including the "true" parameter value with 95% probability, conditional on the model and its underlying assumptions. The full statistical model as well as computer code to reproduce all analyses and figures is available on-line.

## Results

### Search Results
The initial database and registry search yielded 224 studies. Following title and abstract screening, 22 were retained, with the same amount remaining after full-text review.

### Risk of Bias
We concluded that all included studies had low risk of bias.

### Study and Population Characteristics
```{r calculations}
#| echo: false

trials <- data %>% 
  nrow()
patients_total <- with(data, sum(n_c) + sum(n_t)) 
patients_control <- with(data, sum(n_c)) 
patients_treatment <- with(data, sum(n_t)) 
categories <- n_distinct(data$K)
```
The intention to treat population included `r patients_total` participants across `r trials` randomized control trials. `r patients_control` were assigned to medical management, while `r patients_treatment` were assigned to thrombectomy plus medical management.

### Descriptive Results
Observed outcomes in the intention-to-treat cohorts of each trial are reported below.
```{r}
#| echo: false
data <- data %>% 
  mutate(name = c("ANGEL", "RESCUE", "SELECT2", "TENSION", "TESLA",
                   "ESCAPE", "EXTEND", "MRCLEAN", "PISTE", "RESILIENT", "REVASCAT", "SWIFT", "THERAPY", "THRACE",
                   "DAWN", "DEFUSE3", "MRCLEANLATE", "POSITIVE",
                 "ATTENTION", "BAOCHE", "BASICS", "BEST")) %>% 
  relocate("name", .after = J)

data %>% 
  mutate(size = n_c + r_c) %>% 
  mutate(f_c = r_c/n_c) %>% 
  mutate(f_t = r_t/n_t) %>% 
  mutate(rd = r_t/n_t - r_c/n_c) %>% 
  mutate(nnt = 1/rd) %>% 
  mutate(rr = (r_t/n_t) / (r_c/n_c)) %>% 
  select(K, name, size, f_c, f_t, rr, rd, nnt) %>% 
print(n = Inf)
```

The overall pooled data are shown in the following table.
```{r pooled or}
#| echo: false
data %>% 
  summarise(trials = n(),
            size = sum(n_c + n_t),
            r_c = sum(r_c),
            n_c = sum(n_c),
            r_t = sum(r_t),
            n_t = sum(n_t)) %>% 
  mutate(
    f_c = r_c/n_c,
    f_t = r_t/n_t,
    y = log(r_t / (n_t - r_t)) - log(r_c / (n_c - r_c)),
    se = sqrt(1/r_t + 1/(n_t - r_t) + 1/r_c + 1/(n_c - r_c)),
    rd = f_t - f_c,
    nnt = 1/rd,
    rr = f_t/f_c) %>% 
  select(trials, size, f_c, f_t, rr, rd, nnt)
```

The pooled data by category are shown in the following table.
```{r pooled or table}
#| echo: false
data %>% 
  group_by(K) %>% 
  summarise(trials = n(),
            size = sum(n_c + n_t),
            r_c = sum(r_c),
            n_c = sum(n_c),
            r_t = sum(r_t),
            n_t = sum(n_t)) %>% 
  mutate(
    f_c = r_c/n_c,
    f_t = r_t/n_t,
    y = log(r_t / (n_t - r_t)) - log(r_c / (n_c - r_c)),
    se = sqrt(1/r_t + 1/(n_t - r_t) + 1/r_c + 1/(n_c - r_c)),
    rd = f_t - f_c,
    nnt = 1/rd,
    rr = f_t/f_c,
    category = c("EW-LC", "EW-SC", "LW-SC", "BS")
  ) %>% 
  select(category, trials, size, f_c, f_t, rr, rd, nnt)
```

### Treatment effect estimation
```{r treatment group estimates}
#| echo: false
df <- group_summary %>% 
  filter(str_detect(variable, "rd_epred")) %>% 
  select("variable", "median", "mad", "low", "high") 

median1 <- format(df$median[1] * 100, digits = 1)
low1 <- comma(df$low[1] * 100)
high1 <- comma(df$high[1] * 100)

median2 <- format(df$median[2] * 100, digits = 1)
low2 <- comma(df$low[2] * 100)
high2 <- comma(df$high[2] * 100)

median3 <- format(df$median[3] * 100, digits = 1)
low3 <- comma(df$low[3] * 100)
high3 <- comma(df$high[3] * 100)

median4 <- format(df$median[4] * 100, digits = 1)
low4 <- comma(df$low[4] * 100)
high4 <- comma(df$high[4] * 100)
```
Thrombectomy is expected to increase the probability of a favorable outcome in a new trial by `r median2`% (95% PI `r low2`% - `r high2`%) for small stroke treated in an early time window, `r median3`% (95% PI `r low3`% - `r high3`%) for small strokes treated in an late time window, `r median4`% (95% PI `r low4` - `r high4`%) for basilar strokes, and `r median1`% (95% PI `r low1`% - `r high1`%) for large strokes treated in an early time window (figure 1). 

### Clinical importance
```{r}
#| echo: false

# cumulative prob
df <- gq1$draws("rd_epred[1]") 
df1_1 <- format(length(df[df >=.01])/length(df)*100, digits = 2)
df1_10 <- format(length(df[df >= .1])/length(df)*100, digits = 2)
df1_20 <- format(length(df[df >= .2])/length(df)*100, digits = 2)

df <- gq1$draws("rd_epred[2]") 
df2_1 <- format(length(df[df >=.01])/length(df)*100, digits = 2)
df2_10 <- format(length(df[df >= .1])/length(df)*100, digits = 2)
df2_20 <- format(length(df[df >= .2])/length(df)*100, digits = 2)

df <- gq1$draws("rd_epred[3]") 
df3_1 <- format(length(df[df >=.01])/length(df)*100, digits = 2)
df3_10 <- format(length(df[df >= .1])/length(df)*100, digits = 2)
df3_20 <- format(length(df[df >= .2])/length(df)*100, digits = 2)

df <- gq1$draws("rd_epred[4]") 
df4_1 <- format(length(df[df >=.01])/length(df)*100, digits = 2)
df4_10 <- format(length(df[df >= .1])/length(df)*100, digits = 2)
df4_20 <- format(length(df[df >= .2])/length(df)*100, digits = 2)
```
What counts as a clinically important effect size will vary by clinician. We consider three reasonable treatment effect thresholds, and their associated predictive probabilities (figure 2). 

#### Greater than 1% absolute improvement in predicted probability of functional independence
The predicted probability of an effect size greater than 1% in a new trial is about equal across all stroke types, `r df1_1`% for large strokes treated in an early time window, compared to `r df2_1`% for small strokes treated in an early time window, `r df3_1`% for small strokes treated in a late time window, and `r df4_1`% for basilar strokes. A 1% effect size corresponds to a number needed to treat of 100.

#### Greater than 10% absolute improvement in predicted probability of functional independence
The predicted probability of an effect size greater than 10% in a new trial is still very likely for small strokes treated in an early or late time window and for basilar strokes (`r df2_10`%, `r df3_10`%, and `r df4_10`%, respectively), but a little less than a coin flip for large strokes treated in an early time window (`r df1_10`%). A 10% effect size corresponds to a number needed to treat of 10. 

#### Greater than 20% absolute improvement in predicted probability of functional independence
The predicted probability of an effect size greater than 20% in a new trial is a little less than a coin flip for small stroke treated in an early or late time window (`r df2_20`%, `r df3_20`%, respectively), and less likely but still within the realm of possibility for basilar stroke (`r df4_20`%). However, the probability for large strokes treated in an early time window is highly unlikely  (`r df1_20`%). A 20% effect size corresponds to a number needed to treat of 5.

### Baseline risk
```{r control group estimates}
#| echo: false
df <- group_summary %>% 
  filter(str_detect(variable, "x_epred")) %>% 
  select("variable", "median", "mad", "low", "high") 

median1 <- format(df$median[1] * 100, digits = 1)
low1 <- comma(df$low[1] * 100)
high1 <- comma(df$high[1] * 100)

median2 <- format(df$median[2] * 100, digits = 1)
low2 <- comma(df$low[2] * 100)
high2 <- comma(df$high[2] * 100)

median3 <- format(df$median[3] * 100, digits = 1)
low3 <- comma(df$low[3] * 100)
high3 <- comma(df$high[3] * 100)

median4 <- format(df$median[4] * 100, digits = 1)
low4 <- comma(df$low[4] * 100)
high4 <- comma(df$high[4] * 100)
```
Baseline risk -- the predicted probability of achieving the outcome without treatment -- is a key metric that further clarifies the clinical significance of our effect size estimates, but is left out of most meta-analyses. The baseline risk for a patient enrolled in the control arm of a new stroke trial varies widely. In descending order, the probabilities are `r median2`% (95% PI `r low2`% - `r high2`%) for small strokes treated in an early time window, `r median3`% (95% PI `r low3`% - `r high3`%) for small strokes treated in a late time window, `r median4`% (95% PI `r low4` - `r high4`%) for basilar strokes, and `r median1`% (95% PI `r low1`% - `r high1`%) for large strokes treated in an early time window (figure 3).

### Heterogeneity estimation
```{r}
#| echo: false

group_summary <- readRDS(here("fits", "group_summaries.RDS"))
df <- group_summary %>% 
  filter(variable == "I2",
         data == "all", 
         priors == "diffuse") %>% 
  select("variable", "median", "mad", "low", "high") 
i2_med <- comma(df$median*100)
i2_low <- comma(df$low*100)
i2_high <- comma(df$high*100)
```
Estimated treatment effect heterogeneity is an important but often overlooked component of meta-analysis. The Bayesian I-squared statistic, defined as the percent portion of variation in the estimated treatment effect due to between-trial heterogeneity and not sampling variation was `r i2_med`% (95% PI `r i2_low`% - `r i2_high`%). In contrast to frequentist analyses, the I-squared statistic is of less relevance in this Bayesian analysis, since the reported treatment effects themselves are derived from the posterior predictive distributions, which intrinsically incorporate the estimated between-trial heterogeneity. In this sense, and unlike simple average treatment effect estimates from standard meta-analyses, the main results of our model already incorporate the uncertainty deriving from between-trial heterogeneity.

## Discussion
Experts recommend that treatment decisions should be communicated to patients in three steps: establish what outcome matters to the patient, explain their chances without treatment, and describe how treatment changes those chances in absolute terms. Traditional meta-analyses, while statistically rigorous, often fail to provide information in this patient-centered format.

### Importance over signfificance
Our analysis addresses this gap by predicting outcomes for future trials rather than summarizing past ones. By switching the inferential focus to prediction, we are able to uncover important clinical insights heretofore not noted. Despite a statistically significant positive predicted effect in future trials regardless of stroke type, the probability that the predicted effect is clinically important varies substantially (figure 4). This distinction matters for patient care: knowing that thrombectomy 'works' (statistical significance) tells us little about how well it works (clinical importance). 

For example, our analysis finds that in a new trial of small strokes treated in an early time window, there's about a coin flips chance of achieving a remarkably substantial clinical benefit (>20% absolute improvement, or a number needed to treat of 5 or fewer), while the chances of achieving a smaller but still quite large benefit (>10% absolute improvement, number needed to treat of 10) is about 90%. In contrast, for large strokes, while any positive effect remains highly likely, the chance of a "clinically important effect", in the sense defined above, are considerably lower. 

These probability statements provide a more nuanced framework for discussing treatment decisions than simply saying the treatment is "proven effective" - they help clinicians communicate both the promise and limitations of thrombectomy across different stroke types. For example, when counseling a patient with a large stroke, rather than just noting that thrombectomy is "evidence-based", a clinician can explain that while some improvement is very likely, the chance of dramatic benefit is small. This more complete picture helps set appropriate expectations while still supporting the treatment's role.

### Absolute over relative effects
In addition to emphasizing clinical importance over statistical significance, we also stress absolute effect sizes over relative effect sizes, which is reflective of a broader commitment to transparent risk communication in our framework. While relative measures can make treatments seem more dramatic, especially when baseline risks are low, absolute probabilities give patients and families a clearer picture of likely outcomes both with and without treatment. This focus on absolute effects is equally important for clinicians, who might otherwise develop inflated expectations based on impressive-sounding relative effects from trials and meta-analyses. When most patients still have poor outcomes despite treatment - as is often the case with stroke, and especially so for basilar and large core stroke - clinicians might question the trial results or their own practice. Absolute probabilities help avoid this disconnect by keeping both success and failure in proper perspective: even a genuinely effective treatment can leave most patients with poor outcomes when baseline prognosis is poor.

## Limitations
One important potential objection to our approach has to do with our emphasis on prediction. A sophisticated reader might question whether trial-based predictions can guide real-world decisions, since both patients and hospitals outside of trials differ in numerous dimensions from patients and hospitals in trials. We agree, and this observation uncovers the true utility of our approach, which is to use prediction not to forecast specific outcomes, but to understand uncertainty. By focusing on hypothetical future trials, we create a rigorous baseline for discussing how individual patient characteristics might alter expectations. The predicted probabilities aren't precise forecasts, but rather carefully quantified statements about treatment effects under ideal conditions. No actual patients or real hospitals will match these ideal conditions, but they nonetheless provide an excellent baseline. 

Our analyis has three additional important limitations. First, like all Bayesian analyses, our results depend on prior assumptions about model parameters. We addressed this by using clinically informed priors - verified through prior predictive simulation - and checking sensitivity to alternative specifications. These checks, detailed in the supplementary appendix, show our key findings are robust to alternative prior choices. Second, we focused solely on functional independence rather than other outcomes. While a fuller picture of thrombectomy's effects would consider multiple outcomes, functional independence is often most relevant for patient decision-making. Third, we simplified the modified Rankin Scale's six-point gradation of disability into a binary outcome: functionally independent or not. While a more complex model could capture finer distinctions, this simplification makes our results more interpretable for clinical discussions. This reflects our broader approach: managing complexity to produce clear, actionable insights for patient care.

## Conclusions
In this paper, we aimed to show how an extension of the traditional meta-analytic framework using techniques from Bayesian data analysis can be used to derive rigorous yet easily interpretable conclusions about what the current landscape of stroke thrombectomy trials imply for real-world patient care scenarios. Thrombectomy is expected to have a positive effect on the probability of functional independence in a new trial, but the clinical importance of this effect varies by stroke type, and the absolute probability of functional independence is still low -- at best about a coin flip, and in the case of large strokes treated in an early time window, much worse than a coin flip. This information helps calibrate both patient and clinician expectations while supporting thrombectomy's role across stroke types. 
